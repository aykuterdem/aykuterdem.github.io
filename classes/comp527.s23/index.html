<!DOCTYPE HTML>
<!--
	Solarize by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>COMP527/ELEC519: Computational Imaging</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="css/ie/html5shiv.js"></script><![endif]-->
		<script src="js/jquery.min.js"></script>
		<script src="js/jquery.dropotron.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/skel-layers.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel.css" />
			<link rel="stylesheet" href="css/style.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
	</head>
	<body class="homepage">

		<!-- Header Wrapper -->
			<div class="wrapper style1">
			
			<!-- Header -->
				<div id="header">
					<div class="container">
						<!-- Logo -->
							<h1><a href="#" id="logo">COMP527</a></h1>

						<!-- Nav -->
							<nav id="nav">
								<ul>
									<li class="active"><a href="index.html#div_courseinfo">ABOUT</a></li>
									<li><a href="index.html#div_schedule">SCHEDULE</a></li>
									<li><a href="assignments.html">ASSIGNMENTS</a></li>
									<li><a href="project.html">PROJECT</a></li>
									<li><a href="https://ku.blackboard.com">BLACKBOARD</a></li>
									<li><a href="index.html#div_resources">RESOURCES</a></li>
								</ul>
							</nav>
	
					</div>
				</div>
				
			<!-- Banner -->
				<div id="banner">
					<section class="container">
						<h2>COMP527/ELEC519: Computational Imaging</h2>
						<span>Spring 2023</span>
					</section>
				</div>
			</div>
		
		<!-- Course Information -->
			<div class="wrapper style2">
			<section class="container">
				<div id="div_courseinfo">
				<h1 class="content-subhead">Course Information</h1>
				<h2 class="content-subhead">About</h2>
				<p>This course is about <i>computational photography</i>, an emerging new research area which brings together the advancements in computer graphics, computer vision and image processing to overcome the limitations of conventional photography. The course is structured around basic topics such as cameras and image formation, high dynamic range imaging, edge-aware ﬁltering, gradient-domain processing, deconvolution, blending and compositing, visual quality assessment, deep image enhancement, and neural rendering. The goal of this course is to introduce students to a number of different computational techniques to capture, manipulate and enrich visual media</p> 
					
				<p>The main goal of this course is to introduce students to a number of different computational techniques to capture, manipulate and enrich visual media. The students are expected to develop a foundational understanding and knowledge of concepts that underly computational photography. The students will also be expected to gain hands-on experience via a set of programming assignments and a course project.</p> 
				
				<p>The course is taught by <a href="https://aykuterdem.github.io">Aykut Erdem</a>. The teaching assistant is <a href="mailto:abaykal20@ku.edu.tr">Canberk Baykal</a>.
				</p>
				</div>

				<center>
				<a href="https://aykuterdem.github.io" class="image"><img height="12%" width="12%" src="images/aykut-gray.png" alt="" style="border-radius: 50%;border: 1px solid;border-color: #333;"></a>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;		
				<a href="mailto:abaykal20" class="image"><img height="12%" width="12%" src="images/canberk-gray.png" alt="" style="border-radius: 50%;border: 1px solid;border-color: #333;"></a>
				</center></p>
				<h2 class="content-subhead">Time and Location</h2>
				<p><b>Lectures:</b> Monday, Wednesday at 11:30-12:40 (SNA B152)<br>
				<h2 class="content-subhead">Reference Books</h2>
				<p>
				<ul class="default">
				<li  class="li3">Computer Vision: Algorithms and Applications, Richard Szeliski, Second Edition, 2022 (<a href="http://szeliski.org/Book/">pdf</a> available online).</li>
				<li  class="li3">Photography (10th edition), Barbara London, Jim Stone, and John Upton, Pearson, 2010</li>
				<li  class="li3">Computer Vision: A Modern Approach (2nd Edition), David Forsyth and Jean Ponce, Prentice Hall, 2012.</li>
				</ul>	
				</p>
				<p><b>Policies:</b> All work on assignments must be done individually unless stated otherwise. You are encouraged to discuss with your classmates about the given assignments, but these discussions should be carried out in an abstract way. That is, discussions related to a particular solution to a specific problem (either in actual code or in pseudocode) will not be tolerated.</p>
				<p>In short, turning in someone else’s work, in whole or in part, as your own will be considered a violation of academic integrity. Please note that the former condition also holds for the material found on the web, as everything on the web has been written by someone else.</p>
				<h2 class="content-subhead">Communication</h2>
				<p>The course webpage will be updated regularly throughout the semester with lecture notes, presentations, assignments and important deadlines. All other course-related communications will be carried out through Blackboard.</p>
				<h2 class="content-subhead">Pre-requisites</h2>
				<p>Good math (calculus, linear algebra, statistics) and programming skills.</p>
				<h2 class="content-subhead">Course Requirements and Grading</h2>
				<p>Grading for COMP527/ELEC519 will be based on
				<ul class="default">
				<li>Five programming assignments (done individually) (9% each),</li>
				<li>Course project (done in pairs) (30%),</li>
				<li>A midterm exam (20%), and </li>
				<li>Class participation (5%)<br><br></li>
				</ul>
							
			<div id="div_schedule">
  				<h1 class="content-subhead">Schedule</h1>
  				<table class="default">
  				<thead>
  				<tr>
  					<td>Date</td>
  					<td>Topic</td>
  					<td>Notes</td>
  				</tr>
  				</thead>
  				<tbody>
  				  <tr>
		            <td>Feb 27, Mar 1</td>
		            <td>Introduction, Digital photography (<a href="slides/lec1-introduction.pdf">slides</a>)</td>
					<td>Brian Hayes, <a href="resources/CompPhoto.pdf">Computational Photography</a>, American Scientist 96, 94-99, 2008<br>
					Michael Johnston, <a href="https://www.newyorker.com/culture/culture-desk/your-camera-roll-contains-a-masterpiece">Your Camera Roll Contains A Masterpiece</a>, New Yorker, March 31, 2022
</td>
		          </tr>
		    
		          <tr>
		            <td>Mar 6, Mar 8</td>
		            <td>Image formation (<a href="slides/lec2-image-formation.pdf">slides</a>)</td>
		            <td>Szeliski, Chapter 2<br>Forsyth and Ponce, Chapter 1.1<br>Antonio Torralba and William T. Freeman, <a href="https://people.csail.mit.edu/torralba/publications/shadows.pdf">Accidental pinhole and pinspeck cameras</a>, CVPR 2012</td>
		          </tr>
				  
				  <tr>
		            <td>Mar 13, Mar 15</td>
		            <td>Noise and Color (<a href="slides/lec3-noise-color.pdf">slides</a>)<br><b>Assg1 out:</b> Camera Pipeline</td>
					<td>Szeliski, Chapter 2.3, 3.1.2, 10.1<br>Forsyth and Ponce, Chapter 3<br>Michael S. Brown, <a href="https://www.eecs.yorku.ca/~mbrown/CVPR2016_Brown.html">Understanding the In-Camera Image Processing Pipeline for Computer Visions</a>, CVPR 2016 Tutorial<br>S.J. Gortler, <a href="https://sites.fas.harvard.edu/~cs278/papers/colorw.pdf">Chapter 19 (Color)</a> of Foundations of 3D Computer Graphics, MIT Press, 2012</td>
		          </tr>
				  
				  <tr>
		            <td>Mar 20, Mar 22</td>
		            <td>Exposure and high-dynamic-range imaging (<a href="slides/lec4-exposure-hdr-imaging.pdf">slides</a>)</td>
					<td>Szeliski, Chapter 10.1, 10.2<br>Paul E. Debevec and Jitendra Malik, <a href="http://www.pauldebevec.com/Research/HDR/debevec-siggraph97.pdf">Recovering High Dynamic Range Radiance Maps from Photographs</a>, SIGGRAPH 1997<br>Tomoo Mitsunaga and Shree K. Nayar, <a href="https://www1.cs.columbia.edu/CAVE/publications/pdfs/Mitsunaga_CVPR99.pdf">Radiometric Self Calibration</a>, CVPR 1999<br>Erik Reinhard et al., <a href="https://www.cs.utah.edu/docs/techreports/2002/pdf/UUCS-02-001.pdf">Photographic tone reproduction for digital images</a>, CVPR 1999</td>
		          </tr>
				  
				  <tr>
		            <td>Mar 27, Mar 29</td>
		            <td>Image filtering (<a href="slides/lec5-filtering.pdf">slides</a>)<br><b>Assg1 in, Assg2 out:</b> HDR Imaging and Tonemapping</td>
		            <td>Szeliski, Chapter 3.2, 3.3<br>Carlo Tomasi and Roberto Manduchi, <a href="http://www.cs.duke.edu/~tomasi/papers/tomasi/tomasiIccv98.pdf">Bilateral Filtering for Gray and Color Images</a>, ICCV 1998<br>Sylvain Paris et al., <a href="https://people.csail.mit.edu/sparis/bf_course/">A Gentle Introduction to the Bilateral Filter and Its Applications</a>, SIGGRAPH 2008 class<br>Georg Petschnigg et al., <a href="https://hhoppe.com/flash.pdf">Digital photography with flash and no-flash image pairs</a>, SIGGRAPH 2004<br>Kaiming He et al., <a href="http://kaiminghe.com/publications/eccv10guidedfilter.pdf">Guided image filtering</a>, ECCV 2010<br>Antoni Buades et al., <a href="https://www.iro.umontreal.ca/~mignotte/IFT6150/Articles/Buades-NonLocal.pdf">A non-local algorithm for image denoising</a>, CVPR 2005<br>Levent Karacan et al., <a href="https://web.cs.hacettepe.edu.tr/~erkut/publications/RegCovSmoothing.pdf">Structure Preserving Image Smoothing via Region Covariances</a>, SIGGRAPH Asia 2013<br>Qi Zhang et al., <a href="https://lxu.me/mypapers/rollingGuidance.pdf">Rolling Guidance Filter</a>, ECCV 2014</td>
		          </tr>
				  
				  <tr>
		            <td>Apr 3, Apr 5</td>
		            <td>Gradient-domain image processing (<a href="slides/lec6-gradient-domain.pdf">slides</a>)<br><b>Course project proposal due</b></td>
		            <td>Szeliski, Chapter 3.1.3, 3.5.5, 10.4.3<br>Pérez et al., <a href="https://www.cs.jhu.edu/~misha/Fall07/Papers/Perez03.pdf">Poisson Image Editing</a>, SIGGRAPH 2003<br>
					 Agrawal et al., <a href="http://www.amitkagrawal.com/Amit_siggraph2005_flashnoflash_lowres.pdf">Removing Photography Artifacts Using Gradient Projection and Flash-Exposure Sampling</a>, SIGGRAPH 2005<br>
					 Agrawal and Raskar, <a href="http://www.amitkagrawal.com/ICCV2007Course/">Gradient Domain Manipulation Techniques in Vision and Graphics</a>, ICCV 2007 tutorial<br>
					 Bhat et al., <a href="https://grail.cs.washington.edu/projects/gradientshop/">GradientShop: A Gradient-Domain Optimization Framework for Image and Video Filtering</a>, ACM Trans. Graphics, 2010<br>
					 Tumblin et al., <a href="https://www.ics.uci.edu/~majumder/COMPPC/papers/gradientcamera.pdf">Why I want a gradient camera?</a>, CVPR 2005<br>
					 Hua et al., <a href="https://adrien-gruson.com/research/2019_GradientSTAR/">A Survey on Gradient-Domain Rendering</a>, Eurographics 2019 State of the Art Reports (STAR)<br>
					 Gallego et al., <a href="https://rpg.ifi.uzh.ch/docs/EventVisionSurvey.pdf">Event-based Vision: A Survey</a>, IEEE TPAMI, 2020</td>
		          </tr>
				  
				  <tr>
		            <td>Apr 10, Apr 12</td>
		            <td>Focal stacks and lightfields (<a href="slides/lec7-focal-stacks-lightfields.pdf">slides</a>)<br><b>Assg2 in, Assg3 out:</b> Flash/No Flash Photography</b></td>
		            <td>Szeliski, Chapter 12.1.3, 14.3<br>Suwajanakorn et al., <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Suwajanakorn_Depth_From_Focus_2015_CVPR_paper.pdf">Depth from Focus with Your Mobile Phone</a>, CVPR 2015<br>Levoy and Hanrahan, <a href="https://graphics.stanford.edu/papers/light/light-lores-corrected.pdf">Light Field Rendering</a>, SIGGRAPH 1996<br>Gortler et al., <a href="https://cseweb.ucsd.edu/~ravir/6160/papers/p43-gortler.pdf">The Lumigraph</a>, SIGGRAPH 1996<br>Ng et al., <a href="https://graphics.stanford.edu/papers/lfcamera/lfcamera-150dpi.pdf">Light field photography with a hand-held plenoptic camera</a>, Stanford TR 2005-02</td>
		          </tr>
		          
		          <tr>
		            <td>Apr 17, Apr 19</td>
		            <td><i>No class - Spring Break</i></td>
		            <td></td>
		          </tr>
				  
				  <tr>
		            <td>Apr 24, Apr 26</td>
		            <td>Deconvolution, Coded photography <!--(<a href="slides/lec8-deconvolution-coded-photography.pdf">slides</a>)--></td>
					<td>Szeliski, Chapter 3.4.3, 3.4.4, 10.1.4, 10.3<br>R. Fergus et al., <a href="http://people.csail.mit.edu/fergus/papers/deblur_fergus.pdf">Removing camera shake from a single image</a>, SIGGRAPH 2006<br>Cho and Lee, <a href="http://cg.postech.ac.kr/papers/27_Fast-Motion-Deblurring.pdf">Fast motion deblurring</a>, SIGGRAPH Asia 2009<br>Levin et al., <a href="http://people.csail.mit.edu/billf/publications/Understanding_and_Evaluating_Blind.pdf"> Understanding and evaluating blind deconvolution algorithms</a>,CVPR 2009<br>Levin et al., <a href="https://graphics.stanford.edu/courses/cs448a-08-spring/levin-coded-aperture-sig07.pdf">Image and depth from a conventional camera with a coded aperture</a>, SIGGRAPH 2007<br>Levin et al., <a href="https://webee.technion.ac.il/people/anat.levin/papers/MotInv-s-LevinEtAl-SIGGRAPH08.pdf">Motion-Invariant Photography</a>, SIGGRAPH 2008<br>Nagahara et al., <a href="http://www1.cs.columbia.edu/~sujit/Papers/FlexibleDOF_Eccv08.pdf">Flexible depth of field photography</a>, ECCV 2008</td>
		          </tr>
		    
				  <tr>
		            <td>May 3</td>
		            <td>Convolutional Neural Networks <!--(<a href="slides/lec9-convnets.pdf">slides</a>)--><br><b>Assg3 in, Assg4 out:</b> Deep Low-light Image Enhancement</td>
		            <td>Szeliski, Chapter 5.1-5.3</td>
		          </tr>
		          
		          <tr>
		            <td>May 8, May 10</td>
		            <td>Convolutional Neural Networks (cont'd.) <!--(<a href="slides/lec9-convnets.pdf">slides</a>)--><br><b>Project progress reports due</b></td>
		            <td>Szeliski, Chapter 5.4</td>
		          </tr>
				  
				  <tr>
		            <td>May 15, May 17</td>
		            <td>Deep Generative Models and their applications <!--(<a href="slides/lec10-deep-generative-models.pdf">slides</a>)--><br><b>Assg4 in, Assg5 out:</b> Text-driven Image Manipulation</td>
		            <td>Szeliski, Chapter 5.5.4<br>Goodfellow, <a href="https://arxiv.org/abs/1701.00160">Generative Adversarial Networks</a>, NeurIPS 2016 Tutorial</td>
		          </tr>
		          
		          <tr>
		            <td>May 22, May 24</td>
		            <td>Visual quality assessment <!--(<a href="slides/lec11-visual-quality-assessment.pdf">slides</a>)--></td>
					<td>Ma and Fanf, <a href="https://kedema.org/IQA_Tutorial/">Image Quality Assessment in the Modern Age</a>, ACM MM 2021 tutorial<br>Sheikh et al., <a href="https://live.ece.utexas.edu/publications/2006/hrs-transIP-06.pdf">A statistical evaluation of recent full reference image quality assessment algorithms</a>, IEEE TIP 2006<br>Ding et al., <a href="https://arxiv.org/pdf/2005.01338.pdf">Comparison of full-reference image quality assessment models for optimization of image processing systems</a>IJCV 2021<br>Wang and Bovik, <a href="https://live.ece.utexas.edu/publications/2011/wang_spm_2011.pdf">Reduced-and no-reference image quality assessment</a>, IEEE SPM 2011<br>Talebi and Milanfar, <a href="https://arxiv.org/pdf/1709.05424">NIMA: Neural Image Assessment</a>, IEEE TIP 2018<br></td>
		          </tr>
				  
				   <tr>
		            <td>TBA</td>
		            <td><i>Midterm Exam</i></td>
		            <td></td>
		          </tr>
		          
				  <tr>
		            <td>May 29, May 31</td>
		            <td>Advanced topics, Course wrap-up<br><b>Assg5 in</b></td>
		            <td></td>
		          </tr>
				  
				  <tr>
		            <td>June 5, June 7</td>
		            <td>Project presentations<br><b>Final project reports due</b></td>
		            <td></td>
		          </tr>
				  
  				</tbody>
  				</table>
  				
  				
  				<div id="div_resources">
				<h1 class="content-subhead">Resources</h1>
				<h2 class="content-subhead">Related Conferences</h2>
				<ul class="default">
					<li>IEEE International Conference on Computer Vision (ICCV)</li>
					<li>European Conference on Computer Vision (ECCV)</li>
					<li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</li>
					<li>SIGGRAPH</li>
					<li>SIGGRAPH Asia</li>
					<li>IEEE International Conference on Computational Photography (ICCP)</li>
					<li>Advances in Neural Information Processing Systems (NeurIPS)</li>
					<li>International Conference on Learning Representations (ICLR)</li>					
				</ul>
				
				<h2 class="content-subhead">Reference Journals</h2>
				<ul class="default">
					<li>ACM Transactions on Graphics (ACM TOG)</li>
					<li>IEEE Transactions on Image Processing (IEEE TIP)</li>
					<li>IEEE Transactions on Multimedia (IEEE TMM)</li>
					<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI)</li>
					<li>International Journal of Computer Vision (IJCV)</li>
					<li>Computer Vision and Image Understanding (CVIU)</li>
					<li>Image and Vision Computing (IMAVIS)</li>  	
				</ul>
				</ul>
				<h2 class="content-subhead">Python Resources</h2>
				<ul class="default">
  					<li><a href="https://gist.github.com/BurcakAsal/ce60c8de3878362bc008#file-bbm409_python_tutorial-ipynb">Python/numpy Tutorial</a>.</li>
  					<li><a href="http://scikit-learn.org/stable/">scikit-learn</a>: Machine learning in Python</li>
				</ul>
  				<h2 class="content-subhead">Linear Algebra</h2>
  				<ul class="default">
	  				<li><a href="resources/geomLinAlg.pdf">A Geometric Review of Linear Algebra</a>, by Eero Simoncelli</li>
	  				<li><a href="resources/linalg_jordan_86.pdf">An Introduction to Linear Algebra in Parallel Distributed Processing</a>, by M.I. Jordan</li>
	  			</ul>
	  			<h2 class="content-subhead">Resources for scientific writing and talks</h2>
	  			<ul class="default">
		  			<li><a href="http://people.csail.mit.edu/fredo/PUBLI/writing.pdf">Notes on writing</a>, by Fredo Durand</li>
		  			<li><a href="https://www.cis.upenn.edu/~sweirich/icfp-plmw15/slides/peyton-jones.pdf">How to write a great research paper</a>, by Simon Peyton Jones (<a href="http://research.microsoft.com/apps/video/default.aspx?id=151061">video</a>)</li>
		  			<li><a href="resources/guide-presentations.pdf">Small Guide To Giving Presentations</a>, by Markus Püschel</li>
		  			<li><a href="resources/PowerPointPresentation.pdf">Giving an effective presentation: Using Powerpoint and structuring a scientific talk</a>, by Susan McConnell (<a href="http://www.youtube.com/watch?v=Hp7Id3Yb9XQ">video</a>)</li>
		  			<li><a href="resources/TalksAndPapers.pdf">Writing papers and giving talks</a>, by Bill Freeman (<a href="resources/NotesTalksPapers.pdf">notes</a>)</li>
		  		</ul>
				</div>
				</section>
			</div>
			
			

	<!-- Footer -->
		<div id="footer">
			<!-- Copyright -->
				<div id="copyright">
					design: <a href="http://templated.co">templated.co</a> - banner image: An extremely dark image and its enhanced version from Karadeniz et al., IEEE TIP 2021.
				</div>			
		</div>

	</body>
</html>
