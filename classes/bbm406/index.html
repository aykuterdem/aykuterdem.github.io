<!DOCTYPE HTML>
<!--
	Solarize by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>BBM406: Fundamentals of Machine Learning</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script src="css/ie/html5shiv.js"></script><![endif]-->
		<script src="js/jquery.min.js"></script>
		<script src="js/jquery.dropotron.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/skel-layers.min.js"></script>
		<script src="js/init.js"></script>
		<noscript>
			<link rel="stylesheet" href="css/skel.css" />
			<link rel="stylesheet" href="css/style.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
	</head>
	<body class="homepage">

		<!-- Header Wrapper -->
			<div class="wrapper style1">
			
			<!-- Header -->
				<div id="header">
					<div class="container">
						<!-- Logo -->
							<h1><a href="#" id="logo">BBM406</a></h1>

						<!-- Nav -->
							<nav id="nav">
								<ul>
									<li class="active"><a href="index.html#div_courseinfo">About</a></li>
									<li><a href="index.html#div_schedule">Schedule</a></li>
									<li><a href="assignments.html">Assignments</a></li>
									<li><a href="project.html">Project</a></li>
									<li><a href="https://piazza.com/hacettepe.edu.tr/fall2019/bbm406">Piazza</a></li>
									<li><a href="index.html#div_resources">Resources</a></li>
								</ul>
							</nav>
	
					</div>
				</div>
				
			<!-- Banner -->
				<div id="banner">
					<section class="container">
						<h2>BBM406: Fundamentals of Machine Learning</h2>
						<span>Fall 2019</span>
					</section>
				</div>
			</div>
		
		<!-- Course Information -->
			<div class="wrapper style2">
			<section class="container">
				<div id="div_courseinfo">
				<h1 class="content-subhead">Course Information</h1>
				<h2 class="content-subhead">About</h2>
				<p>This is a undergraduate-level introductory course in machine learning (ML) which will give a broad overview of many concepts and algorithms in ML, ranging from supervised learning methods such as support vector machines and decision trees, to unsupervised learning (clustering and factor analysis). The goal is to provide students with a deep understanding of the subject matter and skills to apply these concepts to real world problems. The course is taught by <a href="http://web.cs.hacettepe.edu.tr/~aykut/">Aykut Erdem</a> - the teaching assistant is <a href="mailto:basal@cs.hacettepe.edu.tr">Burcak Asal</a>.
				</p>
				</div>

				<center>
				<a href="http://web.cs.hacettepe.edu.tr/~aykut/" class="image"><img height="12%" width="12%" src="images/aykut.jpg" alt="" style="border-radius: 50%;border: 1px solid;border-color: #333;"></a>
				&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;		
				<a href="mailto:basal@cs.hacettepe.edu.tr" class="image"><img height="12%" width="12%" src="images/burcak.png" alt="" style="border-radius: 50%;border: 1px solid;border-color: #333;"></a>
				</center></p>
				<h2 class="content-subhead">Time and Location</h2>
				<p><b>Lectures:</b> Wednesdays at 09:00-09:50 and Fridays 09:00-10:50 (Room D4)<br>
				<b>Tutorials:</b> Tutorials: Mondays at 15:00-17:00 (Room D8)
				<h2 class="content-subhead">Reference Books</h2>
				<p>
				<ul class="default">
				<li>A Course in Machine Learning, Hal Daumé III (online version (v.0.99) <a href="http://ciml.info">available</a>)</li>
				<li>Artificial Intelligence: A Modern Approach (3rd Edition), Stuart Russell and Peter Norvig. Prentice Hall, 2009</li>
				<li>Bayesian Reasoning and Machine Learning, David Barber, Cambridge University Press, 2012 (online version <a href="http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage">available</a>)</li>
				<li>Introduction to Machine Learning (3rd Edition), Ethem Alpaydin, MIT Press, 2014</li>
				<li>Machine Learning: A Probabilistic Perspective, Kevin Murphy, MIT Press, 2012</li>
				<li>Pattern Recognition and Machine Learning, Christopher Bishop, Springer,  2006 (online version <a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">available</a>)</li>
				</ul>	
				</p>
				<p><b>Policies:</b> All work on assignments must be done individually unless stated otherwise. You are encouraged to discuss with your classmates about the given assignments, but these discussions should be carried out in an abstract way. That is, discussions related to a particular solution to a specific problem (either in actual code or in the pseudocode) will not be tolerated.</p>
				<p>In short, turning in someone else’s work, in whole or in part, as your own will be considered as a violation of academic integrity. Please note that the former condition also holds for the material found on the web as everything on the web has been written by someone else.</p>
				<h2 class="content-subhead">Communication</h2>
				<p>The course webpage will be updated regularly throughout the semester with lecture notes, presentations, assignments and important deadlines. All other course related communications will be carried out through Piazza. Please enroll it by following the link <a href="https://piazza.com/hacettepe.edu.tr/fall2019/bbm406">https://piazza.com/hacettepe.edu.tr/fall2019/bbm406</a>.</p>
				<h2 class="content-subhead">Pre-requisites</h2>
				<p>BBM406 is open to third/fourth-year undergraduate students. Non-CENG graduate students should ask the course instructor for approval before the add/drop period. The prerequisites for this course are:
				<ul class="default">
				<li><u>Programming</u> <i>(you should be a proficient programmer to work out the assignments and to implement your course project.)</i></li>
				<li><u>Calculus</u> <i>(differentiation, chain rule)</i> and Linear Algebra <i>(vectors, matrices, eigenvalues/vectors)</i></li>
				<li><u>Basic Probability and Statistics</u> <i>(random variables, expectations, multivariate Gaussians, Bayes rule, conditional probabilities)</i></li>
				</ul>
				</p>
				<h2 class="content-subhead">Course Requirements and Grading</h2>
				<p>Grading for BBM406 will be based on
				<ul class="default">
				<li>Course project (done in pairs) (30%),</li>
				<li>Midterm exam (30%),</li>
				<li>Final exam (35%), and</li>
				<li>Class participation (5%).<br><br></li>
				</ul>
				</p>
				<p>Grading for BBM409 will be based on
				<ul class="default">
				<li>Quizzes (20%), and</li>
				<li>Three assignments (done individually) which involve both theoretical and programming exercises (20%+30%+30%).</li>
				</ul>
				</p>
							
			<div id="div_schedule">
  				<h1 class="content-subhead">Schedule</h1>
  				<table class="default">
  				<thead>
  				<tr>
  					<td>Date</td>
  					<td>Topic</td>
  					<td>Notes</td>
  				</tr>
  				</thead>
  				<tbody>
  				<tr>
		            <td>Oct 9</td>
		            <td>Course outline and logistics, An overview of Machine Learning [<a href="slides/l1-intro.pdf">slides</a>]</td>
		            <td>Reading: <a href="readings/MachineLearning.pdf">The Discipline of Machine Learning</a>, Tom Mitchell<br>Video 1: <a href="https://www.youtube.com/watch?v=B8J4uefCQMc">The Master Algorithm</a>, Pedro Domingos<br>Video 2: <a href="https://www.youtube.com/watch?v=tXMaFhO6dIY">The Thinking Machine</a><br>Tutorial: <a href="tutorials/week1.ipynb">Python/numpy</a></td>
		          </tr>
		    
		          <tr>
		            <td>Oct 11</td>
		            <td>Machine Learning by Examples, Nearest Neighbor Classifier [<a href="slides/l2-knn.pdf">slides</a>]</td>
		            <td>Reading: Barber 1,14.1-14.2<br>Demo: <a href="http://vision.stanford.edu/teaching/cs231n-demos/knn/">k-Nearest Neighbors</a></td>
		          </tr>
		          
		          <tr>
		            <td>Oct 16</td>
		            <td>Kernel Regression, Distance Functions, Curse of Dimensionality [<a href="slides/l3-kernel_regression.pdf">slides</a>]</td>
		            <td>Reading: Bishop 1.4, 2.5</td>
		          </tr>
		          
		          <tr>
		            <td>Oct 18</td>
		            <td>Linear Regression, Generalization, Model Complexity, Regularization [<a href="slides/l4-linear_regression.pdf">slides</a>]</td>
		            <td>Assg1 out<br>Reading: Bishop 1.1, 3.1, Stanford CS229 <a href="http://www.stanford.edu/class/cs229/notes/cs229-notes1.pdf">note</a><br>Demo: <a href="http://mste.illinois.edu/users/exner/java.f/leastsquares/">Linear regression</a><!--<br>Tutorial: k-NN (<a href="tutorials/week2.zip">notebook</a>)--></td>
		          </tr>
		          
		          <tr>
		            <td>Oct 23</td>
		            <td>Machine Learning Methodology [<a href="slides/l5-ml-methodology.pdf">slides</a>]</td>
		            <td>Reading: P. Domingos, <a href="http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2013/bil682/readings/week4/machine-learning-review-domingos.pdf">A few useful things to know about machine learning</a></td>
		          </tr>
		          
		          <tr>
		            <td>Oct 25</td>
		            <td>Learning Theory, Basic Probability Review [<a href="slides/l6-colt-basic_probability.pdf">slides</a>]</td>
		            <td>Reading: Daume III <a href="http://ciml.info/dl/v0_9/ciml-v0_9-ch10.pdf">12</a>, Barber 1.1-1.4, CIS 520 <a href="https://alliance.seas.upenn.edu/~cis520/wiki/index.php?n=Lectures.ProbabilityReview">note</a><br>E. Simoncelli, <a href="http://www.cns.nyu.edu/~eero/NOTES/geomLinAlg.pdf">A Geometric Review of Linear Algebra</a><br>Video: <a href="http://www.youtube.com/playlist?list=PL17567A1A3F5DB5E4">Probability Primer</a><br>Demo: <a href="https://students.brown.edu/seeing-theory/">Seeing Theory: A visual introduction to probability and statistics</a><br><!--Tutorial: <a href="tutorials/week3.zip">Linear Regression</a>--></td>
		          </tr>
		                
		          <tr>
		            <td>Oct 30</td>
		            <td>Statistical Estimation: MLE [<a href="slides/l7-mle.pdf">slides</a>]</td>
		            <td>Reading: Murphy 2.1-2.3.2<br>Video: Daphne Koller, <a href="https://class.coursera.org/pgm/lecture/index">Probabilistic Graphical Models</a>, <a href="https://www.coursera.org/lecture/probabilistic-graphical-models-3-learning/maximum-likelihood-estimation-KzlS4">MLE Lecture</a>, <a href="https://www.coursera.org/lecture/probabilistic-graphical-models-2-inference/overview-map-inference-JL8Ap">MAP Lecture</a></td>
		          </tr>
		          
		          <tr>
		            <td>Nov 1</td>
		            <td>Statistical Estimation: MAP, Naïve Bayes Classifier [<a href="slides/l8-map-bayes-classifier.pdf">slides</a>]</td>
		            <td>Assg1 due<br>Reading: Daume III <a href="http://ciml.info/dl/v0_9/ciml-v0_9-ch07.pdf">7</a>, <a href="http://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf">Naïve Bayes</a>, Tom M. Mitchell<br>Optional Reading: <a href="readings/mitchell-gnb-fmri.pdf">Learning to Decode Cognitive States from Brain Images</a>, Tom M. Mitchell <i>et al.</i><br>Demo: <a href="http://nbviewer.jupyter.org/github/tfolkman/learningwithdata/blob/master/Bayes_Primer.ipynb">Bayes Theorem</a><!--<br>Tutorial: <a href="tutorials/week4.zip">Cross-validation, Learning Theory, Probability</a>--></td>
		          </tr>
		          
		          <tr>
		            <td>Nov 6</td>
		            <td>Logistic Regression, Discriminant vs. Generative Classification [<a href="slides/l9-logistic_regression.pdf">slides</a>]</td>
		            <td>Reading: SLP3 <a href="https://web.stanford.edu/~jurafsky/slp3/5.pdf">5</a><br>Optional Reading: <a href="readings/nips01-discriminativegenerative">On Discriminative vs. Generative classifiers: A comparison of logistic regression and naive Bayes</a>, Andrew Y. Ng, Michael I. Jordan</td>
		          </tr>
		          
		          <tr>
		            <td>Nov 8</td>
		            <td>Linear Discriminant Functions, Perceptron [<a href="slides/l10-linear-discriminant-functions-perceptron.pdf">slides</a>]</td>
		            <td>Assg2 out<br>Reading: Bishop 4.1.1-4.1.2, 4.5, Daume III <a href="http://ciml.info/dl/v0_9/ciml-v0_9-ch03.pdf">3</a><!--<br>Tutorial: <a href="tutorials/week5.zip">Naive Bayes</a>--></td>
		          </tr>
		          
		          <tr>
		            <td>Nov 13</td>
		            <td>Multi-layer Perceptron [<a href="slides/l11-mlp.pdf">slides</a>]</td>
		            <td><Reading: Bishop Ch. 5.1<br>Video: <a href="https://www.youtube.com/watch?v=0twSSFZN9Mc">Neural Networks</a>, Andrew Ng</td>
		          </tr>
		          
		          <tr>
		            <td>Nov 15</td>
		            <td>Training Neural Networks: Computational Graph, Back-propagation [<a href="slides/l12-backpropagation.pdf">slides</a>]</td>
		            <td>Course project proposal due<br>Reading: CS 231 <a href="http://cs231n.github.io/optimization-2/">Backpropagation notes</a><br>Demo: <a href="http://playground.tensorflow.org">A Neural Network Playground</a><!--<br>Tutorial: <a href="tutorials/week6.pdf">Logistic Regression</a>--></td>
		          </tr>
		          
		          <tr>
		            <td>Nov 20</td>
		            <td>Introduction to Deep Learning [<a href="slides/l13-deep_learning.pdf">slides</a>]</td>
		            <td>Reading: <a href="http://www.readcube.com/articles/10.1038%2Fnature14539">Deep Learning</a>, Yann LeCun, Yoshio Bengio, Geoffrey Hinton</td>
		          </tr>
		          
		          <tr>
		            <td>Nov 22</td>
		            <td>Deep Convolutional Networks [<a href="slides/l14-convnets.pdf">slides</a>]</td>
		            <td>Assg2 due<br>Reading: <a href="http://colah.github.io/posts/2014-07-Conv-Nets-Modular/">Conv Nets: A Modular Perspective</a>, <a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/">Understanding Convolutions</a>, Christopher Olah<!--<br>Tutorial: <a href="tutorials/week7.zip">Neural Networks</a>--></td>
		          </tr>
		          
		          <tr>
		            <td>Nov 27</td>
		            <td>Support Vector Machines (SVMs) [<a href="slides/l15-support_vector_machines.pdf">slides</a>]</td>
		            <td>Reading: Alpaydin 13.1-13.2<br>Video: Patrick Winston, <a href="https://www.youtube.com/watch?v=_PwhiWxHK8o">Support Vector Machines</a></td>
		          </tr>
		          
		          <tr>
		            <td>Nov 29</td>
		            <td>Soft margin SVM, Multi-class SVM [<a href="slides/l16-soft-margin_multi-class_svm-kernels.pdf">slides</a>]</td>
		            <td>Assg3 out<br>Reading: Alpaydin 13.3, 13.9, M.A. Hearst, <a href="http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2013/bil682/supplemental/svm-hearst.pdf">Support Vector Machines</a>, <a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf">CS229 Notes 3.7</a><br>Demo: <a href="http://vision.stanford.edu/teaching/cs231n/linear-classify-demo/">Multi-class SVM demo</a><!--<br>Tutorial: <a href="tutorials/week9.zip">Convolutional Neural Networks</a>--></td>
		          </tr>
		          
		          <tr>
		            <td>Dec 4</td>
		            <td><i>Midterm review</i></td>
		            <td></td>
		          </tr>

		          <tr>
		            <td>Dec 6</td>
		            <td><i>Midterm exam</i></td>
		            <td></td>
		          </tr>
		          
		          <tr>
		            <td>Dec 11</td>
		            <td>Kernels, Kernel Trick for SVMs, Support Vector Regression [<a href="slides/l17-kernel_svm-svr.pdf">slides</a>]</td>
		            <td>Reading: 13.5-13.7, 13.10</td>
		          </tr>
		          
		          <tr>
		            <td>Dec 13</td>
		            <td>Decision Tree Learning [<a href="slides/l18-decision_trees.pdf">slides</a>]</td>
		            <td>Assg3 due<br>Reading: Mitchell <a href="http://www.cs.princeton.edu/courses/archive/spr07/cos424/papers/mitchell-dectrees.pdf">3</a>, Bishop 14.4<br>Demo: <a href="http://www.r2d3.us/visual-intro-to-machine-learning-part-1/">A Visual Introduction to Machine Learning</a><!--<br>Tutorial: <a href="tutorials/week10.zip">SVMs</a>--></td>
		          </tr>
		          
		          <tr>
		            <td>Dec 18</td>
		            <td>Ensemble Methods: Bagging, Random Forests [<a href="slides/l19-bagging-random_forests.pdf">slides</a>]</td>
		            <td>Reading: Bishop 14.1-14.2, <a href="http://scott.fortmann-roe.com/docs/BiasVariance.html">Understanding the Bias-Variance Tradeoff</a>, Scott Fortmann-Roe, <a href="http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm">Random Forests</a>, Leo Breiman and Adele Cutler<br>Optional Reading: <a href="readings/BodyPartRecognition.pdf">Real-Time Human Pose Recognition in Parts from Single Depth Images</a>, Jamie Shotton <i>et al.</i><br>Demo: <a href="http://wise.cgu.edu/portfolio/bootstrapping/">Bootstrapping</a></td>
		          </tr>
		          
		          <tr>
		            <td>Dec 20</td>
		            <td>Ensemble Methods: Boosting [<a href="slides/l20-adaboost.pdf">slides</a>]</td>
		            <td>Project progress reports due<br>Reading: Bishop 14.3<br>Optional Reading: <a href="readings/viola-cvpr-01.pdf">Rapid Object Detection using a Boosted Cascade of Simple Features</a>, Paul Viola and Michael Jones<br>Video: <a href="http://videolectures.net/mlss05us_schapire_b/">A Boosting Tutorial</a>, Robert Schapire<!--<br>Tutorial: <a href="tutorials/week11.zip">Decision Trees</a>--></td>
		          </tr>
		          
		          <tr>
		            <td>Dec 25</td>
		            <td>Clustering: K-Means [<a href="slides/l21-kmeans.pdf">slides</a>]</td>
		            <td>Reading: Bishop 9.1<br><a href="http://www-users.cs.umn.edu/~kumar/dmbook/ch8.pdf">Cluster Analysis: Basic Concepts and Algorithms</a>, Pang-Ning Tan, Michael Steinbach and Vipin Kumar<br>Demo: <a href="http://bl.ocks.org/blacki/c41127e3593052d6cf4e">Visualizing K-Means equilibria</a></td>
		          </tr>
		          
		          <tr>
		            <td>Dec 27</td>
		            <td>Clustering: Spectral Clustering, Agglomerative Clustering [<a href="slides/l22-spectral-hierarchical-clustering.pdf">slides</a>]</td>
		            <td><!--Tutorial: <a href="tutorials/week12.zip">Ensemble Learning</a>--></td>
		          </tr>
		          
		          <tr>
		            <td>Jan 1</td>
		            <td>No class <!--[<a href="slides/l23-pca.pdf">slides</a>]--></td>
		            <td></td>
		          </tr>
		          
		          <tr>
		            <td>Jan 3</td>
		            <td>Dimensionality Reduction: PCA, SVD, ICA, Autoencoders [<a href="slides/l23-dimensionality-reduction.pdf">slides</a>]</td>
		            <td>Reading: Bishop 12.1 Stanford CS229 <a href="http://www.stanford.edu/class/cs229/notes/cs229-notes10.pdf">note</a><br>Optional Reading: <a href="http://www.face-rec.org/algorithms/pca/jcn.pdf">Eigenfaces for Recognition</a>, Matthew Turk and Alex Pentland<br>Video: <a href="http://www.youtube.com/watch?v=ey2PE5xi9-A&feature=PlayList&p=A89DCFA6ADACE599&index=13">PCA</a>, Andrew Ng<br>Demo: <a href="http://setosa.io/ev/principal-component-analysis/">Principal Component Analysis Explained Visually</a><!--Tutorial: <a href="tutorials/week13.zip">Clustering</a>--></td>
		          </tr>
		          
		          <tr>
		            <td>Jan 8</td>
		            <td>Project presentations</td>
		            <td></td>
		          </tr>
		          
		          <tr>
		            <td>Jan 10</td>
		            <td>Project presentations (cont'd.), Course wrap-up</td>
		            <td>Final project reports due<!--<br>Tutorial: <a href="tutorials/week14.zip">PCA</a>--></td>
		          </tr>
  				</tbody>
  				</table>
  				
  				
  				<div id="div_resources">
				<h1 class="content-subhead">Resources</h1>
				<h2 class="content-subhead">Related Conferences</h2>
				<ul class="default">
					<li>Advances in Neural Information Processing Systems (NIPS)</li>
					<li>International Conference on Machine Learning (ICML)</li>
					<li>The Conference on Uncertainty in Artificial Intelligence (UAI)</li>
					<li>International Conference on	Artificial Intelligence and Statistics (AISTATS)</li>
					<li>IEEE International Conference on Data Mining (ICDM)</li>
				</ul>
				<h2 class="content-subhead">Related Journals</h2>
				<ul class="default">
					<li>IEEE Transactions on Pattern Analysis and Machine Intelligence</li>
					<li>Journal of Machine Learning Research</li>
					<li>Data Mining and Knowledge Discovery</li>
					<li>IEEE Transactions on Neural Networks</li>
				</ul>
				<h2 class="content-subhead">Python Resources</h2>
				<ul class="default">
  					<li><a href="https://gist.github.com/BurcakAsal/ce60c8de3878362bc008#file-bbm409_python_tutorial-ipynb">Python/numpy Tutorial</a>.</li>
  					<li><a href="http://scikit-learn.org/stable/">scikit-learn</a>: Machine learning in Python</li>
				</ul>
  				<h2 class="content-subhead">Linear Algebra</h2>
  				<ul class="default">
	  				<li><a href="http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2013/bil682/resources/geomLinAlg.pdf">A Geometric Review of Linear Algebra</a>, by Eero Simoncelli</li>
	  				<li><a href="http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2013/bil682/resources/linalg_jordan_86.pdf">An Introduction to Linear Algebra in Parallel Distributed Processing</a>, by M.I. Jordan</li>
	  			</ul>
	  			<h2 class="content-subhead">Resources for scientific writing and talks</h2>
	  			<ul class="default">
		  			<li><a href="http://people.csail.mit.edu/fredo/PUBLI/writing.pdf">Notes on writing</a>, by Fredo Durand</li>
		  			<li><a href="https://www.cis.upenn.edu/~sweirich/icfp-plmw15/slides/peyton-jones.pdf">How to write a great research paper</a>, by Simon Peyton Jones (<a href="http://research.microsoft.com/apps/video/default.aspx?id=151061">video</a>)</li>
		  			<li><a href="http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2013/bil682/resources/guide-presentations.pdf">Small Guide To Giving Presentations</a>, by Markus Püschel</li>
		  			<li><a href="http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2013/bil682/resources/PowerPointPresentation.pdf">Giving an effective presentation: Using Powerpoint and structuring a scientific talk</a>, by Susan McConnell (<a href="http://www.youtube.com/watch?v=Hp7Id3Yb9XQ">video</a>)</li>
		  			<li><a href="http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2013/bil682/resources/TalksAndPapers.pdf">Writing papers and giving talks</a>, by Bill Freeman (<a href="http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2013/bil682/resources/NotesTalksPapers.pdf">notes</a>)</li>
		  		</ul>
				</div>
				</section>
			</div>
			
			

	<!-- Footer -->
		<div id="footer">
			<!-- Copyright -->
				<div id="copyright">
					design: <a href="http://templated.co">templated.co</a> - banner image: detail from an illustration by <a href="https://www.tomgauld.com">Tom Gauld</a>.
				</div>			
		</div>

	</body>
</html>