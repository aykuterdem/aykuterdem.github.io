<!DOCTYPE HTML>
<!--
	Solarize by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>COMP547: Deep Unsupervised Learning</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<!--[if lte IE 8]><script  src="css/ie/html5shiv.js"></script><![endif]-->
		<script src="js/jquery.min.js"></script>
		<script src="js/jquery.dropotron.min.js"></script>
		<script src="js/skel.min.js"></script>
		<script src="js/skel-layers.min.js"></script>
		<script src="js/init.js"></script>
		<script defer src="https://use.fontawesome.com/releases/v5.0.13/js/all.js"></script>
		<link href="css/fontawesome.css" rel="stylesheet">
		<link href="css/brands.css" rel="stylesheet">
		<noscript>
			<link rel="stylesheet" href="css/skel.css" />
			<link rel="stylesheet" href="css/style.css" />
		</noscript>
		<!--[if lte IE 8]><link rel="stylesheet" href="css/ie/v8.css" /><![endif]-->
	</head>
	<body class="homepage">

		<!-- Header Wrapper -->
			<div class="wrapper style11">
			
			<!-- Header -->
				<div id="header" style="color: #bbb">
					<div class="container">
						<!-- Logo -->
							<h1><a href="#" id="logo">COMP547</a></h1>

						<nav id="nav">
								<ul>
									<li class="active"><a href="index.html#div_courseinfo">About</a></li>
									<li><a href="index.html#div_schedule">Schedule</a></li>
									<li><a href="presentations.html">Presentations</a></li>
									<li><a href="assignments.html">Assignments</a></li>
									<li><a href="project.html">Project</a></li>
									<li>
										<a href="http://ku.blackboard.com"><i class="fas fa-chalkboard"></i></a> &middot;
										<a href="https://join.slack.com/t/comp547/signup"><i class="fab fa-slack fa-lg"></i></a>
									</li>
								</ul>
							</nav>
	
					</div>
				</div>
				
			<!-- Banner -->
				<div id="banner" style="color: black">
					<section class="container">
						<h2>COMP547: Deep Unsupervised Learning</h2>
						<span>Spring 2021</span>
					</section>
				</div>
			</div>

			<!-- Course Information -->
			<div class="wrapper style2">
			<section class="container">
				<h1 class="content-subhead">Detailed Syllabus and Lectures</h1>

<!-- Lecture ## 
   				<hr>
  				<h2>Lecture ##: ## (<a href="slides/lect###.pdf">slides</a>)</h2>
  				<p><i></i></p>
  				<p>Please study the following material in preparation for the class:</p>
  				<h3>Required Reading:</h3>
  				<ul class="default">
  					<li><a href="#">##</a>, ##</li>
  				</ul>
  				<p>
  				<h3>Suggested Video Material:</h3>
  				<ul class="default">
  					<li>'s <a href="#">###</a>, ##</li>
  				</ul><br>
  				</p>
  				<p>
  				<h3>Additional Resources:</h3>
  				<ul class="default">
  					<li></li>
  				</ul>
  				</p>-->
 
 <!-- Lecture 7 
   				<hr>
  				<h2>Lecture 7: Variational Autoencoders (<a href="slides/lect7-variational-autoencoders.pdf">slides</a>)</h2>
				<p><i>latent variable models, variational autoencoders, importance weighted autoencoders, variational lower bound/evidence lower bound, likelihood ratio gradients vs. reparameterization trick gradients, VQ-VAE, Beta-VAE</i></p>
  				<p>Please study the following material in preparation for the class:</p>
  				<h3>Required Reading:</h3>
  				<ul class="default">
  					<li><a href="https://www.deeplearningbook.org/contents/generative_models.html">Sections 20.10.3</a> of the <a href="http://www.deeplearningbook.org/">Deep Learning</a> textbook.</li>
  					<li><a href="https://arxiv.org/pdf/1906.02691.pdf">Chapter 2 of An Introduction to Variational Autoencoders</a>, Kingma and Welling.</li>
  					<li><a href="https://arxiv.org/abs/1509.00519">Importance Weighted Autoencoders</a>, Yuri Burda, Roger B. Grosse, Ruslan Salakhutdinov</li>
  					<li><a href="https://arxiv.org/abs/1312.6114">Auto-Encoding Variational Bayes</a>, Diederik P. Kingma, Max Welling, ICLR 2014.</li>
  					<li><a href="http://proceedings.mlr.press/v80/cremer18a.html">Inference Suboptimality in Variational Autoencoders</a>, Chris Cremer, Xuechen Li, David Duvenaud, ICML 2018.</li>
  					<li><a href="https://openreview.net/pdf?id=Sy2fzU9gl">beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework</a>, Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, Alexander Lerchner, ICLR 2017.</li>
  				</ul>
  				<p>
  				<h3>Suggested Video Material:</h3>
  				<ul class="default">
  					<li><a href="https://www.youtube.com/watch?v=7Pcvdo4EJeo">Modern Latent Variable Models</a> (also includes flow-based models), Andriy Mnih</li>
  				</ul><br>
  				</p>
  				<p>
  				<h3>Additional Resources:</h3>
  				<ul class="default">
	  				<li><a href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf">Variational Inference lecture notes by David Blei. .</li>
	  				<li>[Blog post] <a href="https://yugeten.github.io/posts/2020/06/elbo/">How I learned to stop worrying and write ELBO (and its gradients) in a billion ways</a>, Yuge Shi.</li>
	  				<li>[Blog post] <a href="https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf">Intuitively Understanding Variational Autoencoders</a>, Irhum Shafkat.</li>
  					<li>[Blog post] <a href="https://blog.evjang.com/2016/08/variational-bayes.html">A Beginner's Guide to Variational Methods: Mean-Field Approximation</a>, Eric Jang.</li>
  					<li>[Blog post] <a href="https://jaan.io/what-is-variational-autoencoder-vae-tutorial/">Tutorial - What is a variational autoencoder?</a>, Jaan Altosaar</li>
  					<li>[Blog post] <a href="https://magenta.tensorflow.org/music-vae">MusicVAE: Creating a palette for musical scores with machine learning</a>, Adam Roberts, Jesse Engel, Colin Raffel, Ian Simon, Curtis Hawthorne</li>
  					<li><a href="https://papers.nips.cc/paper/2016/hash/ddeebdeefdb7e7e7a697e1c3e3d8ef54-Abstract.html">Improved Variational Inference with Inverse Autoregressive Flow</a>, Durk P. Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, Max Welling, NIPS 2016.</li>
  					<li><a href="https://openreview.net/forum?id=BJKYvt5lg">PixelVAE: A Latent Variable Model for Natural Images</a>, Ishaan Gulrajani, Kundan Kumar, Faruk Ahmed, Adrien Ali Taiga, Francesco Visin, David Vazquez, Aaron Courville, ICLR 2017.</li>
  					<li><a href="http://proceedings.mlr.press/v97/ho19a.html">Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design</a>, Jonathan Ho, Xi Chen, Aravind Srinivas, Yan Duan, Pieter Abbeel, ICML 2019.</li>
  				</ul>
  				</p> -->
  				
 <!-- Lecture 6 -->
   				<hr>
  				<h2>Lecture 6: Normalizing Flow Models (<a href="slides/lect6-normalizing-flow-models.pdf">slides</a>) (<a href="https://kocuni.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=78ea5e9c-0bbf-4fbc-9c2b-ace500757b4a">video 1</a>) (<a href="https://kocuni.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=7c9e46f3-0b00-4450-a928-ace70075fe50">video 2</a>)</h2>
  				<p><i>1-D flows, change of variables, autoregressive flows, inverse autoregressive flows, affine flows, RealNVP, Glow, Flow++, FFJORD, multi-scale flows, dequantization</i></p>
  				<p>Please study the following material in preparation for the class:</p>
  				<h3>Required Reading:</h3>
  				<ul class="default">
  					<li><a href="https://arxiv.org/abs/1410.8516">NICE: Non-linear Independent Components Estimation</a>, Laurent Dinh, David Krueger, and Yoshua Bengio, ICLR 2015.</li>
  					<li><a href="https://papers.nips.cc/paper/2016/file/ddeebdeefdb7e7e7a697e1c3e3d8ef54-Paper.pdf">Improved variational inference with inverse autoregressive flow</a>, Durk P. Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, Max Welling, NIPS 2016.</li>
  					<li><a href="https://openreview.net/forum?id=HkpbnH9lx">Density estimation using Real NVP</a>, Laurent Dinh, Jascha Sohl-Dickstein, Samy Bengio, ICLR 2017.</li>
  					<li><a href="https://papers.nips.cc/paper/2017/file/6c1da886822c67822bcf3679d04369fa-Paper.pdf">Masked Autoregressive Flow for Density Estimation</a>, George Papamakarios, Theo Pavlakou, Iain Murray, NIPS 2017.</li>
  					<li><a href="http://proceedings.mlr.press/v80/huang18d/huang18d.pdf">Neural autoregressive flows</a>, Chin-Wei Huang, David Krueger, Alexandre Lacoste, Aaron Courville, ICML 2018.</li>
  					<li><a href="https://papers.nips.cc/paper/2018/file/d139db6a236200b21cc7f752979132d0-Paper.pdf">Glow: Generative Flow with Invertible 1×1 Convolutions</a>, Diederik P. Kingma, Prafulla Dhariwal, NeurIPS 2018.</li>
  					<li><a href="http://proceedings.mlr.press/v97/ho19a.html">Flow++: Improving Flow-Based Generative Models with Variational Dequantization and Architecture Design</a>, Jonathan Ho, Xi Chen, Aravind Srinivas, Yan Duan, Pieter Abbeel, ICML 2019.</li>
  					<li><a href="https://arxiv.org/pdf/1808.03856.pdf">Neural Importance Sampling</a>, Thomas Müller, Brian McWilliams, Fabrice Rousselle, Markus Gross, Jan Novák, SIGGRAPH 2019.</li> 					
  					<li><a href="https://openreview.net/forum?id=rJxgknCcK7">Ffjord: Free-form continuous dynamics for scalable reversible generative models</a>, Will Grathwohl, Ricky T. Q. Chen, Jesse Bettencourt, Ilya Sutskever, David Duvenaud, ICLR 2019.</li>
  					  					<li><a href="https://openreview.net/pdf/99885355a0f127b35ddbf715679d8fa3a14e9a99.pdf">Residual Flows for Invertible Generative Modeling</a>, Ricky T. Q. Chen, Jens Behrmann, David Duvenaud, Jörn-Henrik Jacobsen, NeurIPS 2019.</li>
  					<li><a href="http://proceedings.mlr.press/v97/kim19b.html">FloWaveNet : A Generative Flow for Raw Audio</a>, Sungwon Kim, Sang-gil Lee, Jongyoon Song, Jaehyeon Kim, Sungroh Yoon, ICML 2019.</li>
  					<li><a href="">SRFlow: Learning the Super-Resolution Space with Normalizing Flow</a>, Andreas Lugmayr, Martin Danelljan, Luc Van Gool, Radu Timofte, ECCV 2020.</li>
  				</ul>
  				<p>
  				<h3>Suggested Video Material:</h3>
  				<ul class="default">
  					<li><a href="https://www.youtube.com/watch?v=u3vVyFVU_lI">Introduction to Normalizing Flows</a>, Marcus A. Brubaker</li>
  					<li><a href="https://www.youtube.com/watch?v=P4Ta-TZPVi0">A primer on normalizing flows</a>, Laurent Dinh</li> 					
  				</ul><br>
  				</p>
  				<p>
  				<h3>Additional Resources:</h3>
  				<ul class="default">
  					<li><a href="https://arxiv.org/pdf/1908.09257.pdf">Normalizing Flows: An Introduction and Review of Current Methods</a>, Ivan Kobyzev, Simon J.D. Prince, and Marcus A. Brubaker, IEEE PAMI, 2020..</li>
  					<li><a href="https://arxiv.org/pdf/1912.02762.pdf">Normalizing Flows for Probabilistic Modeling and Inference</a>, George Papamakarios, Eric Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, Balaji Lakshminarayanan, arXiv preprint, arXiv:1912.02762, 2019</li>
  					<li>[Blog post] <a href="https://openai.com/blog/glow/">Glow: Better Reversible Generative Models</a>, OpenAI</li>
  					<li>[Blog post] <a href="https://blog.evjang.com/2018/01/nf1.html">Normalizing Flows Tutorial, Part 1: Distributions and Determinants</a>, Eric Jang</li>
  					<li>[Blog post] <a href="https://blog.evjang.com/2018/01/nf2.html">Normalizing Flows Tutorial, Part 2: Modern Normalizing Flows</a>, Eric Jang</li>
  					<li>[Blog post] <a href="https://lilianweng.github.io/lil-log/2018/10/13/flow-based-deep-generative-models.html">Flow-based Deep Generative Models</a>, Lilian Weng</li>
  				</ul>
  				</p>
  				 				
 <!-- Lecture 5 -->
   				<hr>
  				<h2>Lecture 5: Autoregressive Models (<a href="slides/lect5-autoregressive-models.pdf">slides</a>) (<a href="https://kocuni.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=6fddde81-32b1-4004-9a5a-acde0078276e">video 1</a>) (<a href="https://kocuni.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a999c23d-0bfb-479c-9e04-ace0007af1fa">video 2</a>)</h2>
  				<p><i>histograms as simple generative models, parameterized distributions and maximum likelihood, RNN-based autoregressive models, masking-based autoregressive models</i></p>
  				<p>Please study the following material in preparation for the class:</p>
  				<h3>Required Reading:</h3>
  				<ul class="default">
	  				<li><a href="https://www.deeplearningbook.org/contents/generative_models.html">Sections 20.10.5-20.10.10</a> of the <a href="http://www.deeplearningbook.org/">Deep Learning</a> textbook.</li>
  					<li><a href="http://proceedings.mlr.press/v37/germain15.html">MADE: Masked Autoencoder for Distribution Estimation</a>, Mathieu Germain, Karol Gregor, Iain Murray, Hugo Larochelle. ICML 2015.</li>
  					<li><a href="https://arxiv.org/abs/1609.03499">WaveNet: A Generative Model for Raw Audio</a>, Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, Koray Kavukcuoglu. arXiv preprint arXiv:1609.03499, 2016.</li>
  					<li><a href="http://proceedings.mlr.press/v48/oord16.html">Pixel Recurrent Neural Networks</a>, Aaron Van Oord, Nal Kalchbrenner, Koray Kavukcuoglu. ICML 2016.</li>
  					<li><a href="https://papers.nips.cc/paper/2016/hash/b1301141feffabac455e1f90a7de2054-Abstract.html">Conditional Image Generation with PixelCNN Decoders</a>, Aaron van den Oord, Nal Kalchbrenner, Lasse Espeholt, koray kavukcuoglu, Oriol Vinyals, Alex Graves, NIPS 2016.</li>
  					<li><a href="https://openreview.net/forum?id=BJrFC6ceg">PixelCNN++: Improving the PixelCNN with Discretized Logistic Mixture Likelihood and Other Modifications</a>, Tim Salimans, Andrej Karpathy, Xi Chen, Diederik P. Kingma, ICLR 2017.</li>
  					<li><a href="http://proceedings.mlr.press/v80/chen18h.html">PixelSNAIL: An Improved Autoregressive Generative Model</a>, XI Chen, Nikhil Mishra, Mostafa Rohaninejad, Pieter Abbeel. ICML 2018.</li>
  					<li><a href="https://openreview.net/forum?id=rkdF0ZNKl">Fast Generation for Convolutional Autoregressive Models</a>, Prajit Ramachandran, Tom Le Paine, Pooya Khorrami, Mohammad Babaeizadeh, Shiyu Chang, Yang Zhang, Mark A. Hasegawa-Johnson, Roy H. Campbell, Thomas S. Huang. ICLR 2017 Workshop.</li>
  					<li><a href="http://proceedings.mlr.press/v70/reed17a.html">Parallel Multiscale Autoregressive Density Estimation</a>, Scott Reed, Aäron Oord, Nal Kalchbrenner, Sergio Gómez Colmenarejo, Ziyu Wang, Yutian Chen, Dan Belov, Nando Freitas. ICML 2017.</li>
  					<li><a href="http://proceedings.mlr.press/v70/kolesnikov17a.html">PixelCNN Models with Auxiliary Variables for Natural Image Modeling</a>, Alexander Kolesnikov, Christoph H. Lampert. ICML 2017.</li>
  					<li><a href="https://openreview.net/forum?id=HylzTiC5Km">Generating High Fidelity Images with Subscale Pixel Networks and Multidimensional Upscaling</a>, Jacob Menick, Nal Kalchbrenner. ICLR 2019.</li>
  					<li><a href="https://openreview.net/forum?id=rJgsskrFwH">Scaling Autoregressive Video Models</a>, Dirk Weissenborn, Oscar Täckström, Jakob Uszkoreit. ICLR 2020.</li>
  					<li><a href="https://arxiv.org/pdf/1904.10509.pdf">Generating Long Sequences with Sparse Transformers</a>, Rewon Child, Scott Gray, Alec Radford, Ilya Sutskever. arXiv preprint arXiv:1904.10509, 2019.</li>
  					<li><a href="https://arxiv.org/pdf/1912.05015.pdf">Natural Image Manipulation for Autoregressive Models using Fisher Scores</a>, Wilson Yan, Jonathan Ho, Pieter Abbeel. arXiv preprint arXiv:1912.05015, 2019.</li>
  					<li><a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Dahl_Pixel_Recursive_Super_ICCV_2017_paper.pdf">Pixel Recursive Super Resolution</a>, Ryan Dahl, Mohammad Norouzi, Jonathon Shlens. ICCV 2017.</li>
  				</ul>
  				<p>
  				<h3>Suggested Video Material:</h3>
  				<ul class="default">
  					<li><a href="https://www.youtube.com/watch?v=R8fx2b8Asg0">Autoregressive Generative Models with Deep Learning</a>, Hugo Larochelle</li> 
  				</ul><br>
  				</p>
  				<p>
  				<h3>Additional Resources:</h3>
  				<ul class="default">
  					<li>[Blog post] <a href="https://towardsdatascience.com/auto-regressive-generative-models-pixelrnn-pixelcnn-32d192911173">Auto-Regressive Generative Models (PixelRNN, PixelCNN++)</a>, Harshit Sharma, Saurabh Mishra</li>
  				</ul>
  				</p>
 
 <!-- Lecture 4 -->
   				<hr>
  				<h2>Lecture 4: Attention and Transformers (<a href="slides/lect4-attention-and-transformers.pdf">slides</a>) (<a href="https://kocuni.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=630d079a-7f25-496e-8350-acd900774f8e">video</a>)</h2>
  				<p><i>content-based attention, location-based attention, soft vs. hard attention, self-attention, attention for image captioning, transformer networks</i></p>
  				<p>Please study the following material in preparation for the class:</p>
  				<h3>Required Reading:</h3>
	  			<ul class="default">
		  			<li><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a>, D. Bahdanau, K. Cho, Y. Bengio, ICLR 2015</li>
		  			<li>Section 5 of <a href="https://arxiv.org/abs/1308.0850">Generating Sequence with Recurrent Neural Networks</a>, A. Graves, ArXiV</li>
	  				<li><a href="https://distill.pub/2017/ctc/">Sequence Modeling with CTC</a>, Awni Hannun, Distill, 2017</li>
		  			<li><a href="https://papers.nips.cc/paper/5542-recurrent-models-of-visual-attention.pdf">Recurrent Models of Visual Attention</a>, V. Mnih, N. Heess, A. Graves, K. Kavukcuoglu, NIPS 2014</li>
		  			<li><a href="http://proceedings.mlr.press/v37/gregor15.pdf">DRAW: a Recurrent Neural Network for Image Generation</a>, K. Gregor, I. Danihelka, A. Graves, DJ Rezende, D. Wierstra, ICML 2015</li>
		  			<li><a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">Attention Is All You Need</a>, Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin, NIPS 2017</li>
		  		</ul>
	  			</p>
	  			
	  			<p>
	  			<h3>Suggested Video Material:</h3>
	  			<ul class="default">
		  			<li><a href="https://www.youtube.com/watch?v=Keqep_PKrY8">Recurrent Neural Networks and Language Models</a>, Richard Socher</li>
		  			<li><a href="https://www.youtube.com/watch?v=Q57rzaHHO0k">Attention and Memory in Deep Learning</a>, Alex Graves</li>
		  			<li><a href="https://www.youtube.com/watch?v=rBCqOTEfxvg">Attention is all you need attentional neural network models</a>, Łukasz Kaiser</li>
	  			</ul><br>
	  			</p>
	  			<p>	  			
	  			<h3>Additional Resources:</h3>
  				<ul class="default">
	  				<li><a href="https://distill.pub/2016/augmented-rnns/">Attention and Augmented Recurrent Neural Networks</a>, Chris Olah and Shan Carter. Distill, 2016</li>
  					<li>[Blog post] <a href="http://kvfrans.com/what-is-draw-deep-recurrent-attentive-writer/">What is DRAW (Deep Recurrent Attentive Writer)?</a>, Kevin Frans</li>
  					<li>[Blog post] <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a>, Jay Alammar</li>	
		  		
  					<li>[Blog post] <a href="https://lilianweng.github.io/lil-log/2020/04/07/the-transformer-family.html">The Transformer Family</a>, Lilian Weng</li>  				
  					<li><a href="https://arxiv.org/pdf/2102.11972.pdf">Do Transformer Modifications Transfer Across Implementations and Applications?</a>, Sharan Narang et al., arXiv preprint arXiv:2102.11972, 2021.</li>
  					<li><a href="https://arxiv.org/pdf/2101.01169.pdf">Transformers in Vision: A Survey</a>, Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz Khan, and Mubarak Shah, arXiv preprint arXiv:2101.01169, 2021</li>	
  				</ul>
  				</p>
  				  	
 <!-- Lecture 3 -->
   				<hr>
  				<h2>Lecture 3: Sequential Processing with Recurrent Neural Networks (<a href="slides/lect3-sequential-processing.pdf">slides</a>) (<a href="https://kocuni.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=30bab816-978b-4789-8fe4-acd7007680ac">video</a>)</h2>
  				<p><i>sequence modeling, recurrent neural networks (RNNs), RNN applications, vanilla RNN, training RNNs, long short-term memory (LSTM), LSTM variants, gated recurrent unit (GRU)</i></p>
  				<p>Please study the following material in preparation for the class:</p>
  				<h3>Required Reading:</h3>
  				<ul class="default">
  					<li><a href="http://www.deeplearningbook.org/contents/rnn.html">Chapter #10</a> of the <a href="http://www.deeplearningbook.org/">Deep Learning</a> text book.</li>
  					<li>Section 1-3 of <a href="https://arxiv.org/abs/1308.0850">Generating Sequence with Recurrent Neural Networks</a>, A. Graves, ArXiV</li>
		  			
  				</ul>
  				<p>
  				<h3>Suggested Video Material:</h3>
  				<ul class="default">
  					<li>Efstratios Gavves and Max Welling's <a href="http://webcolleges.uva.nl/Mediasite/Play/00584cefc05647a3a47113c749dccac21d">Lecture 8</a></li>
  				</ul><br>
  				</p>
  				<p>
  				<h3>Additional Resources:</h3>
  				<ul class="default">
  					<li>[Blog post] <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a>, Chris Olah.</li>
  					<li>[Blog post] <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a>, Andrej Karpathy.</li>
  					<li><a href="http://www.iro.umontreal.ca/~lisa/pointeurs/ieeetrnn94.pdf">Learning Long-Term Dependencies with Gradient Descest is Difficult</a>, Yoshua Bengio, Patrice Simard, and Paolo Frasconi.</li>
  					<li><a href="http://www.bioinf.jku.at/publications/older/2604.pdf">Long Short-Term Memory</a>, Sepp Hochreiter and Jürgen Schmidhuber.</li>
  				</ul>
  				</p>
  				  				
<!-- Lecture 2 -->  						
  				<hr>
  				<h2>Lecture 2: Neural Networks Basics, Neural Building Blocks I: Spatial Processing with CNNs (<a href="slides/lect2-spatial-processing.pdf">slides</a>) (<a href="https://kocuni.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=5aa8d95a-0865-460a-a904-acd20076d82f">video</a>)</h2>
  				<p><i>deep learning, computation in a neural net, optimization, backpropagation, convolutional neural networks, residual connections, training tricks</i></p>
  				
  				<p>Please study the following material in preparation for the class:</p>
  				<p>
  				<h3>Required Reading:</h3>
  				<ul class="default">
	  				<li><a href="http://www.deeplearningbook.org/contents/optimization.html">Chapter #8</a> and <a href="http://www.deeplearningbook.org/contents/convnets.html">Chapter #9</a> of the <a href="http://www.deeplearningbook.org/">Deep Learning</a> text book.</li>
  				</ul>
  				<p>
  				<h3>Suggested Video Material:</h3>
  				<ul class="default">
  					<li>Andrej Karpathy's Stanford CS231n <a href="https://www.youtube.com/watch?v=LxfUGhug-iQ">Lecture 7</a></li>
  					<li>Kaiming He's tutorial on <a href="https://www.youtube.com/watch?v=C6tLw-rPQ2o">Deep Residual Networks</a></li>
  				</ul><br>
  				</p>
  				<p>
  				<h3>Additional Resources:</h3>
	  			<ul class="default">
		  			<li><a href="https://www.researchgate.net/publication/317496930_Deep_Convolutional_Neural_Networks_for_Image_Classification_A_Comprehensive_Review">Deep Convolutional Neural Networks for Image Classification: A Comprehensive Review</a>, Waseem Rawat and Zenghui Wang. Neural Computation, Vol. 29 , No. 9, 2017</li>
		  			<li><a href="https://distill.pub/2017/momentum/">Why Momentum Really Works</a>, Gabrial Goh. Distill. </li>
		  			<li><a href="https://arxiv.org/pdf/1603.07285.pdf">A guide to convolution arithmetic for deep learning</a>, Vincent Dumoulin and Francesco Visin.</li>
	  				<li><a href="https://arxiv.org/pdf/1511.07122.pdf">Multi-Scale Context Aggregation by Dilated Convolutions</a>, Fisher Yu and Vladlen Koltun. ICLR 2016</li>	
	  				<li><a href="https://arxiv.org/pdf/2102.06171.pdf">High-Performance Large-Scale Image Recognition Without Normalization</a>, Andrew Brock, Soham De, Samuel L. Smith, Karen Simonyan</li>
	  				<li>[Blog post] <a href="https://theaisummer.com/normalization/">In-layer normalization techniques for training very deep neural networks</a>, Nikolas Adaloglou</li>
	  				<li>[Blog post] <a href="http://colah.github.io/posts/2014-07-Understanding-Convolutions/">Understanding Convolutions</a>, Christopher Olah.</li>
  					<li>[Blog post] <a href="https://distill.pub/2016/deconv-checkerboard/">Deconvolution and Checkerboard Artifacts</a>, Augustus Odena, Vincent Dumoulin, Chris Olah.</li>
	  			</ul>
  				</p>
  				
  				<p>
  				<hr>

<!-- Lecture 1 -->  						
  				<hr>
  				<h2>Lecture 1: Introduction to the course (<a href="slides/lect1-introduction.pdf">slides</a>) (<a href="https://kocuni.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=862739e5-72ba-446b-8207-acd0007d4367">video</a>)</h2>
  				<p><i>course information, unsupervised learning</i></p>
  				
  				<p>Please study the following material in preparation for the class:</p>
  				<p>
  				<h3>Required Reading:</h3>
	  			<ul class="default">
		  			<li>[Blog post] <a href="https://jmtomczak.github.io/blog/1/1_introduction.html">Why generative modeling?</a>, Jakub Tomczak. </li>
	  				<li><a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1056774">The Bandwagon</a>, Claude E. Shannon. IRE Transactions on Information Theory, Vol. 2, Issue 3, 1956</li>	
	  			</ul>
  				</p>
  				
  				<p>
  				<hr>
  				</div>
  

	<!-- Footer -->
		<div id="footer">
			<!-- Copyright -->
				<div id="copyright">
					design: <a href="http://templated.co">templated.co</a>
				</div>			
		</div>

	</body>
</html>
