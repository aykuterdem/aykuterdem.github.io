<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Aykut Erdem">

<title>Aykut Erdem</title>
<link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.6.0/pure-min.css">
<link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.6.0/grids-responsive-min.css">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Raleway:200">
</head>

<style>
	html, button, input, select, textarea,
	.pure-g [class *= "pure-u"] {
    /* Set your content font stack here: */
    font-weight: 300;
    font-family: 'Helvetica Neue', 'Source Sans Pro', 'Open Sans',Helvetica,Arial,sans-serif;
    font-size: 15px;
    line-height: 1.4em;
	}

	hr {
    border: 0;
    height: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(255, 255, 255, 0.3);
	}

	body {
		color: #111;
	}
		
	td {
		vertical-align: top;
		padding-right: 1em;
		min-width: 40%;
		padding-bottom: 0.3em;
	}
	h1 {
		font-family: "Raleway", "Helvetica Neue", Helvetica, Arial, sans-serif;
		font-weight: 300;
	}
	
	h2 {
		line-height: 1.2em;
		font-weight: 200;
	}
	
	h3 {
		padding-top: 1em;
		padding-bottom: 0.2em;
		margin-top: 0em;
		margin-bottom: 0em;
	}
	p {
    	padding-bottom: 0.0em;
    	padding-top: 0.0em;
    	margin-top: 0.0em;
    	margin-bottom: 0.0em;
	}

	a {
    	color: #2454a6;
    	text-decoration: none;
	}
	
	b {
		font-weight: 400;
	}
	
	li {
		padding-bottom: 0.5em;
	}
	
	a:hover {
		text-decoration: underline;
	}
	
    .l-box {
        padding-left: 4em;
        padding-right: 2em;
    }
    
    .r-box {
        padding-left: 4em;
        padding-right: 2em;
        margin-left: -2em;
    }
    
    .h-box {
        padding-left: 2em;
        padding-right: 2em;
        padding-top: -2em;
    }
    
    .pub-item {
    padding-top: 0;
    padding-left: 0;
    padding-right: 0em;
    padding-bottom: 1em;
	}
    	.pub-img {
	        border-radius: 3px;
	        margin-right: 0em;
	        width: 80%;
	        
	    }
	    .pub-info {
		    margin-left: -1em;
		    margin-top: 0em;
	    }

</style>

<body>

<div id="main">
	<div class="header">
		<div class="l-box">
			<h1><a href="index.html">Aykut Erdem</a> &middot; <a href="highlights.html">Highlights and News</a></h1>
		</div>
    </div>  

<div class="pure-g">		
	<div class="pure-u-1">
		<div class="l-box">
		<table>
			<b></b>
			<tr>
				<td>Oct 2019</td>
				<td>Our work on manipulating transient attributes of natural scenes via hallucination has been accepted for publication in ACM Transactions on Graphics. Read more about our paper at our <a href="http://hucvl.github.io/attribute_hallucination">project website</a>.</td>
			</tr>
			<tr>
				<td>Aug 2019</td>
				<td>Our paper on multimodal procedural reasoning is accepted to <a href="https://www.conll.org">CoNLL 2019</a>: "Procedural Reasoning Networks for Understanding Multimodal Procedures". Read more about our paper at our <a href="https://hucvl.github.io/prn/">project website</a>.</td>
			</tr>
			<tr>
				<td>Feb 2019</td>
				<td>Our joint work with the <a href="http://www.icon.bilkent.edu.tr/index.html">ICON lab</a> at the National Magnetic Resonance Research Center (UMRAM) on utilizing GANs for multi-contrast MRI image synthesis has been accepted for publication in IEEE Transactions on Medical Imaging. An early version of the manuscript is available on <a href="https://arxiv.org/pdf/1802.01221.pdf">arXiv</a>.</td>
			</tr>
			<tr>
				<td>Feb 2019</td>
				<td>Together with Erkut, I will give a tutorial on Multimodal Learning with Vision and Language at <a href="http://www.ipta-conference.com/ipta19">IPTA 2019</a>.</td>
			</tr>
			
			<tr>
				<td>Dec 2018</td>
				<td>I will give a talk on Multimodal Machine Comprehension at <a href="http://ituro.org/en/">ITURO 2019</a>.</td>
			</tr>		 
			<tr>
				<td>Nov 2018</td>
				<td>RecipeQA was featured by <a href="https://www.technologyreview.com/s/612378/the-quirky-ways-ai-researchers-gather-data-to-feed-their-algorithms/">MIT Technology Review</a> as one of the most creative datasets at EMNLP 2018.</td>
			</tr>
			<tr>
				<td>Aug 2018</td>
				<td>Our paper on multimodal machine comprehension is accepted to <a href="http://emnlp2018.org">EMNLP 2018</a>: "RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes". Read our paper, download the data, and submit your predictions at our <a href="https://hucvl.github.io/recipeqa">project website</a>.</td>
			</tr>
			<tr>
				<td>Aug 2018</td>
				<td>Our work on manipulating transient attributes of natural scenes via hallucination is out on <a href="https://arxiv.org/pdf/1808.07413">arXiv</a>. See our demo and results at <a href="https://web.cs.hacettepe.edu.tr/~karacan/projects/attribute_hallucination/">project website</a></td>
			</tr>
			<tr>
				<td>Jun 2018</td>
				<td>I am invited to Dagstuhl Seminar on <a href="https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=19021">Joint Processing of Language and Visual Data for Better Automated Understanding</a>.</td>
			</tr>
			<tr>
				<td>Mar 2018</td>
				<td>I will be a panelist in a discussion on deep learning at <a href="http://cogsci.boun.edu.tr/isbcs/2018/index.html">ISBCS 2018</a>. Slides of my talk is <a href="talks/towards_visual_intelligence_iscbs18.pdf">here</a>.</td>
			</tr>
			<tr>
				<td>Feb 2018</td>
				<td>I will be teaching a new graduate-level course: <a href="https://web.cs.hacettepe.edu.tr/~aykut/classes/spring2018/cmp784/index.html#div_schedule">CMP 784 Deep Learning</a>. You can follow my deep learning related tweets at <a href="https://twitter.com/aykuterdemml">@aykuterdemml</a>.</td>
			</tr>
			<tr>
				<td>Nov 2017</td>
				<td>Our work on deep dynamic saliency prediction will be published in IEEE Transactions on Multimedia: "Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction".</td>
			</tr>
			<tr>
				<td>Sep 2017</td>
				<td>New TUBITAK 1003 project on "Summarization Approaches Towards Interpreting Big Visual Data", in partnership with <a href="http://www.somera.com.tr/tr/">Somera</a>.</td>
			<tr>
				<td>June 2017</td>
				<td>Our work on sampling-based image and video matting will be published in IEEE Transactions on Image Processing: "Alpha Matting with KL-Divergence Based Sparse Sampling".</td>
			</tr>		
			<tr>
				<td>May 2017</td>
				<td>Slides from our "Adversarial Training and Generative Adversarial Networks" tutorial at SIU 2017 are now <a href="https://vision.cs.hacettepe.edu.tr/siu2017-tutorial/">available online</a>.</td>
			</tr>

<tr>
				<td>Dec 2016</td>
				<td>Our work on evaluation of automatic metrics for image captioning is accepted to EACL 2017 as a long paper: "Re-evaluating Automatic Metrics for Image Captioning". <a href="papers/eacl17slides.pdf">slides</a></td>
			</tr>
			
			<tr>
				<td>Dec 2016</td>
				<td>Our paper on using GANs to generate outdoor scenes from attributes and semantic layouts is out on <a href="https://arxiv.org/abs/1612.00215">arXiv</a>.</td>
			</tr>
			
			<tr>
				<td>Nov 2016</td>
				<td>Our work on learning dynamic saliency will be published in Signal Processing: Image Communication: "A Comparative Study for Feature Integration Strategies in Dynamic Saliency Estimation".</td>
			</tr>
			
			<tr>
				<td>Jul 2016</td>
				<td>Our paper on deep models for dynamic saliency estimation is out on <a href="http://arxiv.org/abs/1607.04730">arXiv</a>.</td>
			</tr>
			
			<tr>
				<td>May 2016</td>
				<td>Slides from our "Deep Learning in Computer Vision" tutorial at SIU 2016 are now <a href="http://vision.cs.hacettepe.edu.tr/siu2016-tutorial/">available online</a>.</td>
			</tr>
			
			<tr>
				<td>May 2016</td>
				<td>Our paper on Turkish image captioning won the Alper Atalay Best Student Paper Award (First Prize) at SIU 2016.</td>
			</tr>
			
			<tr>
				<td>May 2016</td>
				<td>Our paper on photo collection summarization won the IEEE Best Student Paper Award (Second Prize) at SIU 2016.</td>
			</tr>
			
			<tr>
				<td width="11%">Apr 2016</td>
				<td>Our part-based tracking work will be published in Journal of Visual Communication and Image Representation: "Deformable Part-based Tracking by Coupled Global and Local Correlation Filters".</td>
			</tr>
			
			<tr>
				<td>Apr 2016</td>
				<td>Our work on Turkish Image Description Generation is featured on <a href="https://www.youtube.com/watch?v=7wFC-J1Lnzs">national TV</a>.</td>
			</tr>
			
			<tr>
				<td>Mar 2016</td>
				<td>I am awarded a hardware donation (a Tesla K40 GPU) from NVIDIA for my research.</td>
			</tr>
			
			<tr>	
				<td>Feb 2016</td>
				<td>A full paper accepted to Eurographics 2016: "An Objective Deghosting Quality Metric for HDR Images".</td>
			</tr>
			
			<tr>
				<td>Jan 2016</td>
				<td>I'll be speaking at <a href="http://yazgig.com">YAZGIG 2016</a>.</td>
			</tr>
			
			<tr>
				<td>Jan 2016</td>
				<td>We'll be giving a tutorial on deep learning at <a href="http://siu2016.beun.edu.tr">SIU 2016</a>.</td>
			</tr>
			<tr>	
				<td>Sep 2015</td>
				<td>One paper accepted to ICCV 2015: Image Matting with KL-Divergence Based Sparse Sampling.</td>
			</tr>
			
			<tr>	
				<td>Aug 2015</td>
				<td>Journal version of our image memorability work will be published in Image and Vision Computing: Predicting Memorability of Images Using Attention-driven Spatial Pooling and Image Semantics.</td>
			</tr>
			
			<tr>	
				<td>Jun 2015</td>
				<td>One paper accepted to ACL 2015 as a short paper: A Distributed Representation Based Query Expansion Approach for Image Captioning.</td>
			</tr>
			
			<tr>	
				<td>Mar 2015</td>
				<td>A state-of-the-art report (STAR) accepted to Eurographics 2015: The State of the Art in HDR Deghosting: A Survey and Evaluation.</td>
			</tr>
						
			<tr>	
				<td>Oct 2014</td>
				<td>One paper accepted to WACV 2015: City Scale Image Geolocalization via Dense Scene Alignment.</td>
			</tr>
			
			<tr>	
				<td>Jul 2014</td>
				<td>One paper accepted to BMVC 2014: Top down saliency estimation via superpixel-based discriminative dictionaries.</td>
			</tr>
			
			<tr>	
				<td>Jan 2014</td>
				<td>New TÜBİTAK 3501 Career Development Program grant awarded. More details below.</td>
			</tr>
			
			<tr>	
				<td>Sep 2013</td>
				<td>One paper accepted to SIGGRAPH Asia 2013: Structure-Preserving Image Smoothing Via Region Covariances.</td>
			</tr>
			
			<tr>	
				<td>Jul 2013</td>
				<td>New TÜBİTAK 1001 Support Program for Scientific and Technological Research Projects grant awarded. More details below.</td>
			</tr>
			
			<tr>	
				<td>Jun 2013</td>
				<td>Hacettepe University Computer Vision Lab's (HUCVL) website is now online. Visit <a href="http://vision.cs.hacettepe.edu.tr">http://vision.cs.hacettepe.edu.tr</a></td>
			</tr>
			</table>
		
		</div>
	</div>
</div>

</body>
</html>
